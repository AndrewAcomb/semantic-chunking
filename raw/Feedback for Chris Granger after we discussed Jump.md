---
title: "Feedback for Chris Granger after we discussed Jump"
enableToc: false # do not show a table of contents on this page
---
Authored by:: [[P- Rob Haisfield]]

*For context: a while back, I saw a demo of Jump. Jump isn't exactly in stealth but it also isn't something [[P- Chris Granger]] talks about much publicly yet. During our research, we talked with Chris and afterwards, he asked for feedback, so I wrote up a google doc to send to him. With his permission, I've included it here. His comments on the doc were insightful as well, so I've included them as hyperlinks to their own pages.*

Hey Chris, thank you again for taking the time to interview! Most of the Roam and Notion forks are dedicated to making faster horses, meanwhile you're creating a self-driving, KITT augmented hovercraft. It's sort of like the holy grail OS of end-user computing, and I wish you the best of luck with it. Presuming successful execution, I fully expect this to be a paradigm shift. Based on your experience and career leading up to Jump, you're one of the best people to work on it.

You asked for my perspective on what you shared and what you might be missing, and I said I would reflect and get back to you. Your work pre-Jump has given you a complete conceptual framework and thesis. In many ways, [[Q- Does sufficiently advanced natural language processing invalidate the need for a structured DSL|Jump is one possible set of logical conclusions for the questions we've been asking]], and, if you were to look over my knowledge graph, you would likely find it hilarious in its similarity.

It feels almost audacious to say you're missing anything with Jump, as what you revealed in our conversation and the demo are a subset of all of your research. Regardless, I leave this for your consideration. When we have more to share of our own research, I'll appreciate your analysis of what we're missing.

Not making a user tell you something twice is a powerful design principle. I'm sure you will be able to infer a large amount of structure for free. However, I can't shake the feeling that [[CG-comment-1|automatic inferences from my language would deprive me the fine grained control I want]], particularly in creating data structures. I imagine there will have to be some balance. Your molecular schemata approach may be enough. The philosophical difference is that I do not believe revealed preferences are everything. [[CG-comment-2|If a computer can't infer my goals perfectly from my behavior]], then what more powerful tool  do I have than manual controls to tell the computer what exactly my goals are? There is something to a manual tool that gives me 100% legibility over how the computer will interpret my inputs.

I have been exploring the idea of a [[I- A DSL for a discourse graph with information entry, visualization, and retrieval|DSL for synthesis and decision making]] (where the data at the base is not necessarily a text file), and one notion I'm playing with is writing sentences with custom inline data structures. [[CG-comment-3|Nesting blocks within sentences as a replacement for words]]. One could synthesize our approaches — Jump makes the data structures in the background and the user confirms that they are correct.

Generally, I've been exploring what I refer to as "semantic self-expression" in software. For example, [[Roam Research]] infers indentation in an outline to mean branching or nested thought, and encodes that relationship for the sake of querying and filtering linked references. To me, this felt like Roam gave me a way to communicate what was related to what so it could excel at answering my questions. You can find some design suggestions for visualizing those relationships and supporting exploratory browsing in my [onboarding Roamgames submission](https://www.figma.com/file/5shwLdUCHxSaPNEO7pazbe/Dhrumil%26Robert---RoamGames-Challenge-2?node-id=0%3A1). Other mechanisms that fall within your selection and refactoring framework include conditional formatting, possibly where the conditions are synthesized by the computer after the user has manually formatted information, possibly through something like Codex Editor's standoff annotation.

I want to be sure that those schemata are not just what's formed from the dictionary and thesaurus, but also that I am [[CG-comment-4|appending custom phrases and coinages as I go]]. The dictionary and thesaurus provide information, but the phrases for how I compose labeled ideas is more important. I do not expect most interdisciplinary conceptual links to share words. (See Andy Matuschak's [note titles as APIs](https://notes.andymatuschak.org/z3XP5GRmd9z1D2qCE7pxUvbeSVeQuMiqz9x1C) and arguments for [concept oriented notes](https://notes.andymatuschak.org/z6bci25mVUBNFdVWSrQNKr6u7AZ1jFzfTVbMF))

You chose to organize exploratory browsing such that it would maximize surprise in the information theory sense of the word — it must communicate something new that does not feel trivial to the perceiver. I'm not sure  the implications on user behavior would be to this. If your system is actively guiding people in their exploration, then you have a responsibility to guide appropriately. We've seen downstream implications of social media newsfeed algorithm optimizations so it's an important design space.

However, computer augmented synthesis as a series of scaffolded surprises is certainly a compelling idea. It’s rare to see a behavioral perspective this refined. As such, I believe that the process of synthesis can be made intensely fun for participants through explicit choices.

Along those lines, I've been playing with two things. One is that the [[CG-comment-5|the choice architecture can present choices]] that [[C- User behavior within a well-designed choice architecture can be a signal of preferences|reveal user preferences]], similar to how we were talking about how the most useful thing a user can do is reveal their goals and have a conversation with Jump. Another is that there are fascinating interface possibilities with respect to giving users direct feedback loops and [[CG-comment-5|control over the algorithms]] serving them content.

To reveal user preferences on an exploratory browsing/search interface, one approach would be allowing people to [[C- Highlighted and lowlighted search results map to how well results map to intentions|emphasize and de-emphasize information]], and encode the searches and their results accordingly. If queries are statements of intent, result prioritization is a confirmation that the computer has an accurate model.

Your notion of building out a molecular schema that filters down the overall knowledge graph based on only the information it has and local context radiating outward is powerful. When people say they like an app because it works like their brain does, they don't know what’s coming. In your position, I would strongly consider how you can infer what is the most contextually relevant information based on how people write, lay out information, and relate it. I expect your refactoring tools will enable people to adjust structure top down as well.

I think you are underestimating the sheer amount of information that can be gathered from crowdsourced user behavior from many people performing varied roles on the same content. Leaving questions for others to answer, emphasizing and de-emphasizing content, curating trails, curating curated trails, etc. Additionally, given how much you have reduced the friction to add metadata to content, a crowdsourced semantic web may become more feasible than it was before.

It also appears that you have not fully considered social coordination design to support lofty augmented collective thinking goals. As we discussed, this is a behavioral influence question, and as you mentioned, some percentage of the difficulty here has to do with current incentives around sharing. However, [[CG-comment-6|your goal seems more neutral about what people will do with Jump]], so that may not be important.

Tokens—financial, reputational, or otherwise, can support overall social coordination. For example, compensating users for supporting other users (answering questions, building plugins, leading onboarding sessions, etc.). However, crypto Web3 people haven't fully considered how software design influences user behavior and overweight tokens.

You mentioned that people don't always know what questions they are asking. The best thing to provide them with is an exploratory browsing experience. I wonder if, in those situations, there might be opportunities to prompt awareness and help them formulate a question. Your hypothesis that browsing with expanded context will lead them to generate a question is valid.

[[I- Search as a primitive|Selection]], refactoring, and copies are a solid set of primitive concepts. [[CG-comment-7|The workflows to search]] / browse and work with that information as users go are crucial. For example, in Roam, one of their expectations is that as you're browsing backlinks or query results, you block reference them into an outline in the Daily Notes and annotating what you have determined as important, or editing results in place. Obsidian's search is arguably more complete, but incorporating the results into your current thinking is more difficult due to the UX because it shows all of the results but requires you to click and navigate. If you look at [part three of my Roamgames submission,](https://www.figma.com/file/5shwLdUCHxSaPNEO7pazbe/Dhrumil%26Robert---RoamGames-Challenge-2?node-id=0%3A1) you will see an interface that shows relevant notes, updates legibly based on new information, and enables the user to manually emphasize and de-emphasize relationships. That's all based on indentation, the slider, and filters. What's missing is an intelligent backend that's able to interpret the user inputs and log those _in conjunction with_ the searches as a meaningful input for the future.

I would keep pulling at the Gigjam string. People bringing their knowledge graphs together [[CG-comment-8|without sharing too much of the total graph]] is not an easy problem at all and [keeps Joel Chan up at night](https://twitter.com/JoelChan86/status/1309521782806847490?s=20&t=Y2_Y5xPm7X6NJAfkfO2_0A).

A few miscellaneous thoughts that came to mind as we were going:

-   I would prompt you to think more about [[CG-comment-9|how multiple people think together in Jump.]] Apps like Roam make the implicit assumption that synthesis happens in one mind. A computer augmenting a person is powerful, but so is a computer/other people. I believe that scaffolding built for decentralized synthesis looks a lot like a social network (with different goals than social media).
-   You often said things like "there ought to be a way for the system to recognize the conceptual similarity" and my first thought each time was to replace "system" with "multi-human/computer system." [[CG-comment-10|In your thought experiment, everything that requires difficult behavior change seems to be left to the computer]]. I'll be pondering that for a while.
-   The insight that the most useful thing a user can do is reveal their goals explicitly and have a conversation with the tool is powerful. Additionally, that common goals for a domain can be prebuilt, it's just that nobody does it.
-   Creating programs in the background for users is a powerful notion. A key problem we’ve noticed in a lot of our user interviews is aspirational systems that people can’t seem to keep up with. This may be a way to decrease entropy over the entire system as quantity increases.
-   Apart from knowledge management, I want to use Jump to handle my DeFi taxes. I'm imagining uploading CSVs, making rules about how I want interactions with certain smart contracts to be treated. Many DeFi users are feeling the pain of waiting for tax software developers to update and include new protocols given the rapid pace of innovation.
-   I would love to chat with you about your user research in this space. It's clear how zooming out on your career, your work on Microsoft's assisted coding, Light Table, Eve, and Looker all played into your product-instantiated insights for Jump, but it's also clear that you studied your users more than most.
-   I'd love to hear you elaborate on, "Decentralized apps with a P2P backend feel different than cloud based apps in that you build a more direct relationship with it."
